{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests package to request webpage information\n",
    "import requests\n",
    "# Import BeautifulSoup to parse HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping data:\n",
    "Following code, pulls recipes from a website which lists Indian breakfast recipes(182 recipes). I have just pulled the data, and have not made any modification to the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.padhuskitchen.com/2010/09/breakfast-recipes-indian-breakfast.html')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "recipe_links=[]\n",
    "recipe_name=[]\n",
    "s_recipe=soup.find(\"select\",{\"name\" : \"Breakfast\"})\n",
    "s_recipe2=s_recipe.find_all(\"option\")\n",
    "\n",
    "for link in s_recipe2:\n",
    "    if link.has_attr('value'):\n",
    "        recipe_links.append(link['value'])\n",
    "recipe_links1=[x for x in recipe_links if x not in [\"\"]]\n",
    "\n",
    "raw_ing=pd.DataFrame(columns=[\"url\",\"name\",\"ingredient\"])\n",
    "\n",
    "def recipe_pull(link,raw_ing):\n",
    "    #print(link)\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    ing_list = soup.find_all(\"span\", {\"itemprop\" : \"ingredients\"})\n",
    "    \n",
    "    recipe_name = soup.find('h3',{\"class\" : \"post-title entry-title\"})\n",
    "    \n",
    "    for i in ing_list:\n",
    "        lst_dict = []\n",
    "        lst_dict.append({'url':link, 'name':recipe_name.get_text(\"\",strip=True), 'ingredient': i.get_text(\"\",strip=True)})\n",
    "        raw_ing=raw_ing.append(lst_dict, ignore_index=True)\n",
    "    return(raw_ing)\n",
    "    \n",
    "\n",
    "for i in range(len(recipe_links1)-1):\n",
    "    raw_ing=recipe_pull(recipe_links1[i],raw_ing)\n",
    "\n",
    "raw_ing.to_csv(\"a2_rawData.csv\",encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data:\n",
    "This website has ingredients with quantity. To ensure only ingredients are captured, I have tried to remove irrelevant words, numbers, blanks & special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ing=pd.DataFrame()\n",
    "clean_ing=raw_ing.copy()\n",
    "\n",
    "\n",
    "for i in range(len(raw_ing)):\n",
    "    \n",
    "    comment_words = []\n",
    "    stopwords = list(STOPWORDS) \n",
    "    stopwords1=stopwords+[\"\",\"i\",\"½\",\"¼\",\"(\",\")\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"–\",\"-\",\"cup\",\"tbsp\",\"tsp\",\"needed\",\"chopped\",\"finely\",\"used\",\"medium\",\n",
    "             \"large\",\"small\",\"size\",\"deseeded\"]\n",
    "    stopwords2 = [\"1/2\",\"1/4\",\"3/4\",\"big\",\"pinch\",\"\",\"cup\",\"cups\",\"tbsp\",\"tsp\",\"needed\",\"chopped\",\"finely\",\"used\",\"–\",\"-\",\"½\",\"¼\",\"medium\",\"(\",\")\",\"large\",\"small\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"–\",\"-\",\n",
    "      \"size\",\"deseeded\",\"inch\",\"(without)\",\"piece\",\"seeds\",\"pinch\",\"to\",\"taste\",\"(optional)\",\"optional\",\"whole\",\"flat\",\"for\",\"dusting\",\"or\",\"chopped\",\n",
    "                 \"finely\",\"kitchen\",\"fistful\",\"without\",\"crushed\",\"slightly\",\"required\",\"king\",\"making\",\"leaves\",\"a\",\"as\",\"12\",\"11\",\"10\",\"7\",\"8\",\"9\",\"green\",\"powder\",\"grated\",\"clean\"]\n",
    "    \n",
    "    val=raw_ing.iloc[i,2]\n",
    "    tokens = val.lower()\n",
    "    tokens=tokens.replace(\"-\",\" \")\n",
    "    tokens=tokens.replace(\"/\",\" \")\n",
    "    tokens=tokens.replace(\"(\",\" \")\n",
    "    tokens=tokens.replace(\")\",\" \")\n",
    "    tokens=tokens.strip()\n",
    "    tokens1 = tokens.split()\n",
    "    resultwords  = [word for word in tokens1 if word.lower() not in stopwords2]\n",
    "    tokens2 = ' '.join(resultwords)\n",
    "    clean_ing[\"ingredient\"][i]=tokens2.strip()\n",
    "    \n",
    "clean_ing.to_csv(\"a2_cleanData.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Popular Ingredients:\n",
    "Code below calculates the Top 10 ingredients, # times it has occured in all the recipes & proportion of recipes which have the ingredient.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important thing to note is that, for some recipes, it has sub modules like: Curry powder preparation part, Main item preparation part etc. In those cases, ingredient might be listed twice. (eg) In https://www.padhuskitchen.com/2011/01/ven-pongal-ven-pongal-with-sambar.html , salt is listed twice. So, count of salt will be 2. But for proportion calculation, it would be counted only as 1 recipe in which salt has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sakura\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ing_words=[]\n",
    "clean_ing2=pd.DataFrame()\n",
    "clean_ing2=clean_ing.copy()\n",
    "for i in range(len(clean_ing2)):\n",
    "    val=clean_ing2.iloc[i,2].split()\n",
    "    for j in val:\n",
    "        j.lower()\n",
    "        ing_words.append(j.lower())\n",
    "\n",
    "ing_grp=dict(Counter(ing_words))\n",
    "\n",
    "ing_dt=pd.DataFrame.from_dict(ing_grp,orient=\"index\")\n",
    "ing_dt1=ing_dt.reset_index()\n",
    "ing_dt1.columns=['word','count']\n",
    "ing_dt1.sort_values(by=['count'],inplace=True,ascending=False)\n",
    "ing_top10=ing_dt1.head(10)\n",
    "ingtop10 = ing_top10.reset_index(drop=True)\n",
    "\n",
    "for i in range(10):\n",
    "    x=ingtop10.iloc[i,0]\n",
    "    clean_ing2[x]=0\n",
    "for i in range(len(clean_ing2)):\n",
    "    val=clean_ing2.iloc[i,2].split()\n",
    "    for j in val:\n",
    "        for k in range(10):\n",
    "            l=k+3\n",
    "            if j.strip() == ingtop10.iloc[k,0].strip():\n",
    "                x=ingtop10.iloc[k,0]\n",
    "                clean_ing2[x][i]=1\n",
    "        \n",
    "for k in range(10):\n",
    "    ing_c=0\n",
    "    x=pd.DataFrame(clean_ing2.groupby(['url']).sum()[ingtop10.iloc[k,0]])\n",
    "    for j in range(len(x)):\n",
    "        if x.iloc[j,0] > 0:\n",
    "            ing_c=ing_c+1\n",
    "    ingtop10.loc[k,2]=ing_c/len(x)\n",
    "ingtop10.columns=['word','count','proportion']\n",
    "ingtop10.to_csv(\"a2_results.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
